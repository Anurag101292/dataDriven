âœ… 1. What is performance testing and why is it important?
Answer:
Performance testing is a type of non-functional testing used to determine how a system behaves under expected and peak load conditions.
 It checks the responsiveness, stability, scalability, and speed of the application.

ğŸ” Example: You test how your banking application behaves when 10,000 users log in simultaneously during salary day.

âœ… 2. How does performance testing differ from functional testing?
Answer:

Functional Testing checks what the system does (correctness of features).

Performance Testing checks how fast and how well the system performs under various loads.

ğŸ’¡ In QA automation: Functional test passes when login works; performance test checks if login completes in 
under 2 seconds for 1000 concurrent users.

âœ… 3. What are the different types of performance testing?
Answer:
Load Testing â€“ checks system under expected user load.
Stress Testing â€“ checks system under extreme load until it breaks.
Spike Testing â€“ sudden large increase/decrease in load.
Endurance (Soak) Testing â€“ long-duration load test.
Scalability Testing â€“ test how well system scales.
Volume Testing â€“ large data (e.g., big DB records) test.

âœ… Use Case: Simulating 50,000 users uploading documents or running 24-hour tests to catch memory leaks.

âœ… 4. What is baseline testing?
Answer:
Baseline testing captures the system's performance under normal load before any optimization. 
It becomes the reference point for future tests.

ğŸ“ˆ Example: If API latency is 1.2 seconds today, this is your baseline. After optimization, you compare against it.

âœ… 5. What is the difference between throughput and latency?
Answer:
Throughput: Number of requests served per unit of time (e.g., 200 requests/sec).
Latency: Time taken to serve a request (e.g., 500 ms per API call).
ğŸ¯ Throughput = system capacity
ğŸ•’ Latency = individual request time

âœ… 6. What is think time and why is it important?
Answer:
Think time simulates the real delay between actions of a user (e.g., reading a page before clicking next).
 Ignoring it makes the test unrealistically aggressive.

Example in JMeter:
Add â†’ Think Time Timer â†’ 3000ms (3 seconds)
Use inside Thread Group â†’ Add â†’ Timer â†’ Constant Timer (3000 ms)
âœ… 7. What is ramp-up period in performance testing?
Answer:
Ramp-up is the time taken to gradually add users during a test. This avoids sudden spikes and simulates real traffic growth.

ğŸ§ª Example: Ramp-up 100 users over 10 minutes = 10 users per minute.

âœ… 8. What is the difference between concurrent users and simultaneous users?
Answer:
Concurrent Users: All users who are active (may not hit the server at the same time).
Simultaneous Users: All users who hit the server at the exact same time.
Concurrent = Logged-in and browsing
Simultaneous = Click "Submit" at the same second

âœ… 9. What is response time vs. turnaround time?
Answer:
Response Time: Time from request to first byte received.
Turnaround Time: Total time from request initiation to completion (includes client-side processing).
ğŸ” Example: API call responds in 2s (response), but UI renders in 5s (turnaround).

âœ… 10. What metrics do you typically monitor during performance testing?
Answer:
Response Time   Throughput     Error Rate             CPU/Memory Usage
Disk I/O        Thread Count   GC Time (JVM apps)     Network Bandwidth
Tools like JMeter + Grafana + InfluxDB help visualize this live.
